import streamlit as st
import pandas as pd
import numpy as np
import pickle
import re
from kospellpy import spell_init
from tqdm import tqdm
import torch
from transformers import BertTokenizer, BertForSequenceClassification
import openai
import plotly.express as px
import time
import matplotlib.pyplot as plt
from matplotlib import font_manager, rc

# OpenAI API í‚¤ ì„¤ì •
openai.api_key = ''

# í°íŠ¸ ì„¤ì •
font_name = font_manager.FontProperties(fname='fonts\\NanumBarunGothic.ttf').get_name()
rc('font', family=font_name)


# ë°ì´í„° íƒ€ì… ìµœì í™” í•¨ìˆ˜
def optimize_dtypes(dataframe):
    for column in dataframe.columns:
        col_type = dataframe[column].dtype

        # ê²°ì¸¡ì¹˜ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ë°ì´í„° íƒ€ì… ë³€ê²½
        if not dataframe[column].isnull().any():
            if col_type != object:
                c_min = dataframe[column].min()
                c_max = dataframe[column].max()

                if str(col_type)[:3] == 'int':
                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                        dataframe[column] = dataframe[column].astype(np.int8)
                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                        dataframe[column] = dataframe[column].astype(np.int16)
                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                        dataframe[column] = dataframe[column].astype(np.int32)
                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                        dataframe[column] = dataframe[column].astype(np.int64)

                else:
                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                        dataframe[column] = dataframe[column].astype(np.float16)
                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                        dataframe[column] = dataframe[column].astype(np.float32)
                    else:
                        dataframe[column] = dataframe[column].astype(np.float64)
            else:
                dataframe[column] = dataframe[column].astype('category')

    return dataframe


# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
def clean_text(text):
    if isinstance(text, str):
        text = re.sub(r'[^ê°€-í£0-9a-zA-Z\s.]', '', text)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        text = text.replace('\n', '')  # ê°œí–‰ë¬¸ì ì œê±°
        return text
    else:
        return ""


# # ë¬¸ì¥ ë¶„ë¦¬ í•¨ìˆ˜
# def split_sentences(df, column):
#     split_df = df[column].str.split('.').apply(lambda x: pd.Series(x)).stack().reset_index(level=1, drop=True).to_frame(column).reset_index(drop=True)
#     split_df = split_df[split_df[column].str.strip() != ''].reset_index(drop=True)
#     return split_df

# ë©”ì¸ ì•± ì½˜í…ì¸ 
def main_page():
    try:
        # í˜ì´ì§€ ì œëª©
        st.title('VoC ë°ì´í„° ë¶„ì„ğŸ“Š')

        # í˜ì´ì§€ ì„¤ëª…
        st.write('''
            ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê³ , ê´€ì‹¬ ìˆëŠ” ê²°ê³¼ë¥¼ ì–»ì–´ë³´ì„¸ìš”.
        ''')

        st.sidebar.title('ğŸ—£ï¸VoC ë°ì´í„° ë¶„ì„')

        # ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ
        uploaded_file = st.sidebar.file_uploader("ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ (CSV, Excel, Pickle)", type=['csv', 'xlsx', 'pickle'])
        df = None

        # ì—…ë¡œë“œëœ íŒŒì¼ë¡œë¶€í„° ë°ì´í„°í”„ë ˆì„ ë¡œë“œ
        if uploaded_file is not None:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
            elif uploaded_file.name.endswith('.xlsx'):
                df = pd.read_excel(uploaded_file)
            elif uploaded_file.name.endswith(('.pkl', '.pickle')):
                df = pickle.load(uploaded_file, encoding='utf-8-sig')

            # ë°ì´í„° íƒ€ì… ìµœì í™”
            df = optimize_dtypes(df)

            # í…ìŠ¤íŠ¸ ì¹¼ëŸ¼ ì„ íƒ
            if df is not None:
                target_column = st.sidebar.selectbox("í…ìŠ¤íŠ¸ ë³€ìˆ˜ ì„ íƒ", df.columns)
                st.session_state['target_column'] = target_column  # ì„¸ì…˜ ìƒíƒœì— í…ìŠ¤íŠ¸ ì¹¼ëŸ¼ ì €ì¥

            # ë©”ì¸ ì½˜í…ì¸  ì˜ì—­
            tab1, tab2, tab3, tab4, tab5 = st.tabs(['N/N+ Sentence', 'ê°ì • ë¶„ì„', 'ê°œì„ /ë¶ˆë§Œ ë¶„ì„', 'ê·¸ë£¹í•‘', 'ëª¨ë¸ í™œìš©'])

            with tab1:
                # ì›ë³¸ =í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë°ì´í„° ë°ì´í„°í”„ë ˆì„ ìƒì„±
                origin = df[target_column]
                origin_df = origin.apply(clean_text)
                st.session_state['origin_df'] = origin_df

                split_df = pd.read_csv("voc_script_ìƒì†Œë¦¬_500_N+.csv")

                # ì›ë³¸ ë°ì´í„°
                st.markdown('#### N sentence')
                st.dataframe(origin_df, height=400, width=700)

                # ë°ì´í„°í”„ë ˆì„ì„ CSVë¡œ ë³€í™˜
                csv = origin_df.to_csv(index=False).encode('cp949')

                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìƒì„±
                st.download_button(
                    label="ë‹¤ìš´ë¡œë“œ",
                    data=csv,
                    file_name='origin_sentences.csv',
                    mime='text/csv',
                )

                # ë¬¸ì¥ ë¶„ë¦¬ëœ ë°ì´í„°
                st.markdown('#### N+ sentence')
                st.dataframe(split_df, height=400, width=700)

                # ë°ì´í„°í”„ë ˆì„ì„ CSVë¡œ ë³€í™˜
                csv = split_df.to_csv(index=False).encode('cp949')

                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìƒì„±
                st.download_button(
                    label="ë‹¤ìš´ë¡œë“œ",
                    data=csv,
                    file_name='split_sentences.csv',
                    mime='text/csv',
                )

                st.markdown('#### N/N+ sentence ë¹„êµ')
                values = []
                for column in split_df.columns:
                    values.extend(split_df[column].replace('', pd.NA).dropna().tolist())
                new_df = pd.DataFrame(values, columns=['ì˜ê²¬'])
                st.session_state['new_df'] = new_df

                # ë§‰ëŒ€ê·¸ë˜í”„ ì‹œê°í™”
                count_data_chart = pd.DataFrame({
                    'Type': ['N sentence', 'N+ sentence'],
                    'Count': [origin_df.shape[0], new_df.shape[0]]
                })
                fig = px.bar(count_data_chart, x='Type', y='Count', color='Type',
                             color_discrete_map={'N sentence': 'lightblue', 'N+ sentence': 'blue'})
                st.plotly_chart(fig)

                # í‘œ í˜•íƒœ
                count_data_table = pd.DataFrame({
                    'N sentence': [origin_df.shape[0]],
                    'N+ sentence': [new_df.shape[0]]
                }, index=['ê°œìˆ˜'])
                st.table(count_data_table)

            with tab2:
                # ê°ì • ë¶„ì„
                st.markdown('#### ê°ì • ë¶„ì„')
                sentiment = pd.read_excel("voc_scipt_ìƒì†Œë¦¬_500_N+_ë¶„ë¥˜ì˜ˆì¸¡.xlsx")
                sentiment = sentiment.drop(columns='label1')

                label_counts = sentiment['label2'].value_counts()
                label_percentages = (label_counts / label_counts.sum()) * 100

                label_counts_formatted = label_counts.apply(lambda x: f"{x:d}")
                label_percentages_formatted = label_percentages.apply(lambda x: f"{x:.2f}")

                label_summary = pd.DataFrame({
                    'ê°œìˆ˜': label_counts_formatted,
                    'ë¹„ìœ¨': label_percentages_formatted
                }).transpose()

                # fig, ax = plt.subplots()
                # ax.pie(label_counts, labels=label_counts.index, autopct='%1.1f%%', startangle=90)
                # ax.axis('equal')
                # st.pyplot(fig)

                plot = pd.DataFrame({'label': label_counts.index, 'count': label_counts.values})
                fig = px.pie(plot, values='count', names='label', hole=0.3)
                st.plotly_chart(fig)

                st.table(label_summary)

                # ê³µë°± ì¶”ê°€
                st.markdown("<br><br>", unsafe_allow_html=True)

                for label in label_counts.index:
                    st.markdown(f"#### {label} ê°ì •")
                    label_data = sentiment[sentiment['label2'] == label][['SCRIPT']]
                    st.dataframe(label_data, height=400, width=700)

                    # ë°ì´í„°í”„ë ˆì„ì„ CSVë¡œ ë³€í™˜
                    csv = label_data.to_csv(index=False).encode('cp949')

                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìƒì„±
                    st.download_button(
                        label="ë‹¤ìš´ë¡œë“œ",
                        data=csv,
                        file_name=f'{label}_sentences.csv',
                        mime='text/csv',
                    )

            with tab3:
                # ë¶ˆë§Œ/ê°œì„  ë¶„ì„
                st.markdown('#### ë¶ˆë§Œ/ê°œì„  ë¶„ì„')
                sentiment = pd.read_excel("voc_scipt_ìƒì†Œë¦¬_500_N+_ë¶„ë¥˜ì˜ˆì¸¡.xlsx")
                sentiment = sentiment.drop(columns='label2')

                label_counts = sentiment['label1'].value_counts()
                label_percentages = (label_counts / label_counts.sum()) * 100

                label_counts_formatted = label_counts.apply(lambda x: f"{x:d}")
                label_percentages_formatted = label_percentages.apply(lambda x: f"{x:.2f}")

                label_summary = pd.DataFrame({
                    'ê°œìˆ˜': label_counts_formatted,
                    'ë¹„ìœ¨': label_percentages_formatted
                }).transpose()

                # fig, ax = plt.subplots()
                # ax.pie(label_counts, labels=label_counts.index, autopct='%1.1f%%', startangle=90)
                # ax.axis('equal')
                # st.pyplot(fig)

                plot = pd.DataFrame({'label': label_counts.index, 'count': label_counts.values})
                fig = px.pie(plot, values='count', names='label', hole=0.3)
                st.plotly_chart(fig)

                st.table(label_summary)

                # ê³µë°± ì¶”ê°€
                st.markdown("<br><br>", unsafe_allow_html=True)

                for label in label_counts.index:
                    st.markdown(f"#### {label} ì˜ê²¬")
                    label_data = sentiment[sentiment['label1'] == label][['SCRIPT']]
                    st.dataframe(label_data, height=400, width=700)

                    # ë°ì´í„°í”„ë ˆì„ì„ CSVë¡œ ë³€í™˜
                    csv = label_data.to_csv(index=False).encode('cp949')

                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìƒì„±
                    st.download_button(
                        label="ë‹¤ìš´ë¡œë“œ",
                        data=csv,
                        file_name=f'{label}_sentences.csv',
                        mime='text/csv',
                    )

            with tab4:
                st.markdown('#### ê·¸ë£¹í•‘')

            with tab5:
                st.markdown('#### ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸')

                def load_model(model_path):
                    model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=3)
                    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
                    model.eval()
                    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')
                    return model, tokenizer

                def predict(text, model, tokenizer):
                    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)
                    with torch.no_grad():
                        outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])
                        predictions = torch.argmax(outputs.logits, dim=-1)
                        predicted_label = predictions.item()
                    return predicted_label

                # ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
                model_path = "model_state_multi_language_ì ¤ì˜ë‚˜ì˜´.pth"
                model, tokenizer = load_model(model_path)

                # ë¼ë²¨ ë§µí•‘
                label_map = {0: 'ê¸ì •', 1: 'ë¶€ì •', 2: 'ì¤‘ë¦½'}

                # ì‚¬ìš©ì ì…ë ¥
                user_input = st.text_input("ê°ì • ë¶„ì„ì„ ìœ„í•œ í…ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”")

                if st.button("ì˜ˆì¸¡í•˜ê¸°"):
                    if user_input:
                        prediction = predict(user_input, model, tokenizer)
                        st.markdown(
                            f"""
                            <div style="background-color: #f0f0f5; padding: 10px; border-radius: 5px; border: 1px solid #ddd;">
                                <h5>ì˜ˆì¸¡ ë¼ë²¨</h5>
                                <p>{label_map[prediction]}</p>
                            </div>
                            """, unsafe_allow_html=True)
                    else:
                        st.write("ì˜ˆì¸¡ì„ ìœ„í•œ í…ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”")

                # ê³µë°± ì¶”ê°€
                st.markdown("<br><br>", unsafe_allow_html=True)

                st.markdown('#### ê°œì„ /ë¶ˆë§Œ ë¶„ì„ í…ŒìŠ¤íŠ¸')

                def load_model(model_dir):
                    model = BertForSequenceClassification.from_pretrained(model_dir)
                    tokenizer = BertTokenizer.from_pretrained(model_dir)
                    return model, tokenizer

                def predict(text, model, tokenizer):
                    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)
                    with torch.no_grad():
                        outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])
                        predictions = torch.argmax(outputs.logits, dim=-1)
                        predicted_label = predictions.item()
                    return predicted_label

                # ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
                model_dir = "ê°œì„ ë¶ˆë§Œì˜ˆì¸¡ëª¨ë¸"
                model, tokenizer = load_model(model_dir)

                # ë¼ë²¨ ë§µí•‘
                label_map = {0: 'ê°œì„ ', 1: 'ë¶ˆë§Œ', 2: 'ì—†ìŒ'}

                # ì‚¬ìš©ì ì…ë ¥
                user_input = st.text_input("ê°œì„ /ë¶ˆë§Œ ë¶„ì„ì„ ìœ„í•œ í…ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”")

                if st.button("ì˜ˆì¸¡í•˜ê¸°", key="predict_button"):
                    if user_input:
                        prediction = predict(user_input, model, tokenizer)
                        st.markdown(
                            f"""
                            <div style="background-color: #f0f0f5; padding: 10px; border-radius: 5px; border: 1px solid #ddd;">
                                <h5>ì˜ˆì¸¡ ë¼ë²¨</h5>
                                <p>{label_map[prediction]}</p>
                            </div>
                            """, unsafe_allow_html=True)
                    else:
                        st.write("ì˜ˆì¸¡ì„ ìœ„í•œ í…ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”")

    except UnicodeDecodeError as e:
        st.error("ì—…ë¡œë“œí•œ íŒŒì¼ì˜ ì¸ì½”ë”© í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. UTF-8 ì¸ì½”ë”© í˜•ì‹ìœ¼ë¡œ íŒŒì¼ì„ ì €ì¥í•´ì£¼ì„¸ìš”.")


main_page()
